{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## English"
      ],
      "metadata": {
        "id": "yfMo10XJyie5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkL3qIhCymsn",
        "outputId": "98a9ead4-43d5-4698-bc5e-bb3d3a0af502"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-12 19:24:03--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-12-12 19:24:03--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.08MB/s    in 2m 39s  \n",
            "\n",
            "2022-12-12 19:26:42 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-d1iFT9y-x7",
        "outputId": "8bc5d583-a411-4292-8fee-6d6f1e0f1da6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found {} word vectors'.format(len(embeddings_index)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76BAKLyByxA2",
        "outputId": "dce01138-0330-4a69-da9c-1fc4ad726d70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_glove_data(text):\n",
        "  for word in text.split():\n",
        "    if word in embeddings_index.keys():\n",
        "      print('\\x1B[32m' '\"{}\" word found'.format(word))\n",
        "    else:\n",
        "      print('\\x1B[30m' '\"{}\" word not found'.format(word))"
      ],
      "metadata": {
        "id": "z4LddN5c3vFv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'This is just a sample text for the purpose of testing'.lower()\n",
        "check_glove_data(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m94sEto1yyKf",
        "outputId": "a3e1234b-21b8-4ef0-ef24-86e90e7ef681"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\"this\" word found\n",
            "\u001b[32m\"is\" word found\n",
            "\u001b[32m\"just\" word found\n",
            "\u001b[32m\"a\" word found\n",
            "\u001b[32m\"sample\" word found\n",
            "\u001b[32m\"text\" word found\n",
            "\u001b[32m\"for\" word found\n",
            "\u001b[32m\"the\" word found\n",
            "\u001b[32m\"purpose\" word found\n",
            "\u001b[32m\"of\" word found\n",
            "\u001b[32m\"testing\" word found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization"
      ],
      "metadata": {
        "id": "B3mMdS2qzjsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lemmatization(text, model):\n",
        "  doc = model(text)\n",
        "  return \" \".join([token.lemma_ for token in doc])"
      ],
      "metadata": {
        "id": "2gajxepQ3PbU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_en = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "EXpFRo261Z0w"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_lemma = get_lemmatization(sentence, nlp_en)\n",
        "sentence_lemma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X2HTfZPc1jsL",
        "outputId": "223987f0-54b9-46d7-d246-efc8f4f535dd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this be just a sample text for the purpose of testing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_glove_data(sentence_lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muYHyicQ4gG-",
        "outputId": "67fcf9b1-5450-4742-f88b-ed78b1adaf4c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\"this\" word found\n",
            "\u001b[32m\"be\" word found\n",
            "\u001b[32m\"just\" word found\n",
            "\u001b[32m\"a\" word found\n",
            "\u001b[32m\"sample\" word found\n",
            "\u001b[32m\"text\" word found\n",
            "\u001b[32m\"for\" word found\n",
            "\u001b[32m\"the\" word found\n",
            "\u001b[32m\"purpose\" word found\n",
            "\u001b[32m\"of\" word found\n",
            "\u001b[32m\"testing\" word found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_2 = 'I am hanging out in a garden'\n",
        "sentence_lemma = get_lemmatization(sentence_2, nlp_en).lower()\n",
        "sentence_lemma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TVFb9b7q2K4M",
        "outputId": "e00b094c-69fe-450c-f276-af3a40ce920c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i be hang out in a garden'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_glove_data(sentence_lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5rj_3Z62hda",
        "outputId": "d1116719-7a9a-4ac9-8384-dcf3f6215708"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\"i\" word found\n",
            "\u001b[32m\"be\" word found\n",
            "\u001b[32m\"hang\" word found\n",
            "\u001b[32m\"out\" word found\n",
            "\u001b[32m\"in\" word found\n",
            "\u001b[32m\"a\" word found\n",
            "\u001b[32m\"garden\" word found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spanish"
      ],
      "metadata": {
        "id": "FhZMm11t3Dgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz\n",
        "!gzip -dv glove-sbwc.i25.vec.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoteY1Im3Dj3",
        "outputId": "bcce2586-9c97-4f21-8ead-927a80963a56"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove-sbwc.i25.vec.gz:\t 61.2% -- replaced with glove-sbwc.i25.vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvectors = KeyedVectors.load_word2vec_format('glove-sbwc.i25.vec', limit=50000)"
      ],
      "metadata": {
        "id": "WBLHHZYT8C2F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_glove_data(text):\n",
        "  for word in text.split():\n",
        "    if word in wordvectors.vocab.keys():\n",
        "      print('\\x1B[32m' '\"{}\" word found'.format(word))\n",
        "    else:\n",
        "      print('\\x1B[30m' '\"{}\" word not found'.format(word))"
      ],
      "metadata": {
        "id": "WyiURsu-Ahgf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_es = 'Esta película fue genial'.lower()\n",
        "check_glove_data(sentence_es)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A0l78eQ8C4m",
        "outputId": "c941b4c8-0f6b-411c-c90d-a154470c3f9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\"esta\" word found\n",
            "\u001b[32m\"película\" word found\n",
            "\u001b[32m\"fue\" word found\n",
            "\u001b[32m\"genial\" word found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_es = 'yo creo que es la mejor actriz del mundo'.lower()\n",
        "check_glove_data(sentence_es)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoH6D2_ZA8uh",
        "outputId": "56501004-dad6-49b6-e074-4d51cae6d284"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\"yo\" word found\n",
            "\u001b[32m\"creo\" word found\n",
            "\u001b[32m\"que\" word found\n",
            "\u001b[32m\"es\" word found\n",
            "\u001b[32m\"la\" word found\n",
            "\u001b[32m\"mejor\" word found\n",
            "\u001b[32m\"actriz\" word found\n",
            "\u001b[32m\"del\" word found\n",
            "\u001b[32m\"mundo\" word found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization"
      ],
      "metadata": {
        "id": "-YUEZzQMA8wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download es_core_news_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SENWNum32A2C",
        "outputId": "a50dc64f-4b25-4586-fd0e-1a394fc130df"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2022-12-12 19:38:17.464660: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting es-core-news-md==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.4.0/es_core_news_md-3.4.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.3 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from es-core-news-md==3.4.0) (3.4.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (8.1.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (0.10.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (1.10.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.0.1)\n",
            "Installing collected packages: es-core-news-md\n",
            "Successfully installed es-core-news-md-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_es = spacy.load('es_core_news_md')"
      ],
      "metadata": {
        "id": "pYLoLTO5BUMQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_es = 'Esta pelicula fue genial'.lower()\n",
        "sentence_lemma = get_lemmatization(sentence_es, nlp_es)\n",
        "sentence_lemma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qhoRLCIUBL6p",
        "outputId": "6b3712c7-f707-40ad-f723-ff8a5e43cdb4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este pelicula ser genial'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_glove_data(sentence_lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVkSv59gBhM7",
        "outputId": "ee865545-8741-4577-d22b-a4d9e9de728d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\"este\" word found\n",
            "\u001b[32m\"pelicula\" word found\n",
            "\u001b[32m\"ser\" word found\n",
            "\u001b[32m\"genial\" word found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_es = 'yo creo que es la mejor actriz del mundo'.lower()\n",
        "sentence_lemma = get_lemmatization(sentence_es, nlp_es)\n",
        "sentence_lemma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fy5Q-9BSBL9O",
        "outputId": "121cec76-2547-439c-a65e-5632e492f4c3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yo creer que ser el mejor actriz del mundo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_glove_data(sentence_lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSeOvxzaBL_k",
        "outputId": "8a2fccd8-8e31-4fcb-cdd4-ca3fa8d1e90f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\"yo\" word found\n",
            "\u001b[32m\"creer\" word found\n",
            "\u001b[32m\"que\" word found\n",
            "\u001b[32m\"ser\" word found\n",
            "\u001b[32m\"el\" word found\n",
            "\u001b[32m\"mejor\" word found\n",
            "\u001b[32m\"actriz\" word found\n",
            "\u001b[32m\"del\" word found\n",
            "\u001b[32m\"mundo\" word found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_es = 'la mayor posibilidad en todas las opciones'.lower()\n",
        "sentence_lemma = get_lemmatization(sentence_es, nlp_es)\n",
        "sentence_lemma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SjpqPfFGBMBr",
        "outputId": "67c7d76b-a075-41ac-a497-2b60737d0bb7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'el mayor posibilidad en todo el opción'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_glove_data(sentence_lemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkSJY_d9Bvmq",
        "outputId": "452011f2-d9b3-47b2-eee1-3a1676e20b79"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\"el\" word found\n",
            "\u001b[32m\"mayor\" word found\n",
            "\u001b[32m\"posibilidad\" word found\n",
            "\u001b[32m\"en\" word found\n",
            "\u001b[32m\"todo\" word found\n",
            "\u001b[32m\"el\" word found\n",
            "\u001b[32m\"opción\" word found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvectors.get_vector('posibilidad').shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZTtc_BeByuF",
        "outputId": "87c20075-dcdb-48f7-bf86-80303ab31edc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvectors.wv.most_similar(positive=['mujer', 'rey'], negative=['hombre'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciihUfwEDyB5",
        "outputId": "4868603c-acb0-41c2-a810-018c73270b15"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-93a36401aa39>:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  wordvectors.wv.most_similar(positive=['mujer', 'rey'], negative=['hombre'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('reina', 0.6732203364372253),\n",
              " ('isabel', 0.5993215441703796),\n",
              " ('monarca', 0.5833542346954346),\n",
              " ('princesa', 0.5566387176513672),\n",
              " ('hija', 0.5369765162467957),\n",
              " ('infanta', 0.5317001938819885),\n",
              " ('esposa', 0.5256122350692749),\n",
              " ('alfonso', 0.5193145275115967),\n",
              " ('iv', 0.5174581408500671),\n",
              " ('ii', 0.5153015851974487)]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvectors.wv.most_similar(positive=['gato', 'tigre'], negative=['perro'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O5I6WooPjOo",
        "outputId": "55f891a6-de2b-4041-8486-b38d3c12e97a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-9e7835da2092>:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  wordvectors.wv.most_similar(positive=['gato', 'tigre'], negative=['perro'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('venado', 0.4637227952480316),\n",
              " ('leopardo', 0.44934844970703125),\n",
              " ('puma', 0.4475456178188324),\n",
              " ('juniors', 0.4290238320827484),\n",
              " ('felinos', 0.42076990008354187),\n",
              " ('montés', 0.4189727306365967),\n",
              " ('boca', 0.39804211258888245),\n",
              " ('zorro', 0.3968369662761688),\n",
              " ('pez', 0.39571985602378845),\n",
              " ('elefante', 0.39226317405700684)]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvectors_en = KeyedVectors.load_word2vec_format('glove.6B.100d_2.txt', binary=False, encoding=\"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "3-Npp70iMtFB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordvectors_en.wv.most_similar(positive=['woman', 'king'], negative=['man'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T7PsSqvPAy8",
        "outputId": "155d8fa5-c20b-49f9-914c-1ece4953168c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-150515658f50>:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  wordvectors_en.wv.most_similar(positive=['woman', 'king'], negative=['man'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7698541283607483),\n",
              " ('monarch', 0.6843380928039551),\n",
              " ('throne', 0.6755735874176025),\n",
              " ('daughter', 0.6594556570053101),\n",
              " ('princess', 0.6520534753799438),\n",
              " ('prince', 0.6517034769058228),\n",
              " ('elizabeth', 0.6464517712593079),\n",
              " ('mother', 0.6311717629432678),\n",
              " ('emperor', 0.6106470823287964),\n",
              " ('wife', 0.6098655462265015)]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordvectors_en.wv.most_similar(positive=['cat', 'tiger'], negative=['dog'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyNOHfMjPA1Q",
        "outputId": "c41dc520-b228-4514-86e9-f9d5fed02245"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-57-35631f7094e9>:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  wordvectors_en.wv.most_similar(positive=['cat', 'tiger'], negative=['dog'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('leopard', 0.6474355459213257),\n",
              " ('tigers', 0.6170241832733154),\n",
              " ('crocodile', 0.5733538866043091),\n",
              " ('elephant', 0.5629477500915527),\n",
              " ('dragon', 0.5605452060699463),\n",
              " ('lion', 0.5505025386810303),\n",
              " ('rhino', 0.5312058925628662),\n",
              " ('tamil', 0.5310259461402893),\n",
              " ('elephants', 0.5188644528388977),\n",
              " ('turtle', 0.5155850648880005)]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reformat GloVe Original output"
      ],
      "metadata": {
        "id": "WYe-7zOCNC8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import smart_open\n",
        "from sys import platform\n",
        "\n",
        "import gensim\n",
        "\n",
        "\n",
        "def prepend_line(infile, outfile, line):\n",
        "\t\"\"\" \n",
        "\tFunction use to prepend lines using bash utilities in Linux. \n",
        "\t(source: http://stackoverflow.com/a/10850588/610569)\n",
        "\t\"\"\"\n",
        "\twith open(infile, 'r') as old:\n",
        "\t\twith open(outfile, 'w') as new:\n",
        "\t\t\tnew.write(str(line) + \"\\n\")\n",
        "\t\t\tshutil.copyfileobj(old, new)\n",
        "\n",
        "def prepend_slow(infile, outfile, line):\n",
        "\t\"\"\"\n",
        "\tSlower way to prepend the line by re-creating the inputfile.\n",
        "\t\"\"\"\n",
        "\twith open(infile, 'r') as fin:\n",
        "\t\twith open(outfile, 'w') as fout:\n",
        "\t\t\tfout.write(line + \"\\n\")\n",
        "\t\t\tfor line in fin:\n",
        "\t\t\t\tfout.write(line)\n",
        "\n",
        "def get_lines(glove_file_name):\n",
        "    \"\"\"Return the number of vectors and dimensions in a file in GloVe format.\"\"\"\n",
        "    with smart_open.smart_open(glove_file_name, 'r') as f:\n",
        "        num_lines = sum(1 for line in f)\n",
        "    with smart_open.smart_open(glove_file_name, 'r') as f:\n",
        "        num_dims = len(f.readline().split()) - 1\n",
        "    return num_lines, num_dims\n",
        "\t\n",
        "# Input: GloVe Model File\n",
        "# More models can be downloaded from http://nlp.stanford.edu/projects/glove/\n",
        "glove_file=\"glove.6B.100d.txt\"\n",
        "\n",
        "num_lines, dims = get_lines(glove_file)\n",
        "\n",
        "# Output: Gensim Model text format.\n",
        "gensim_file='glove.6B.100d_2.txt'\n",
        "gensim_first_line = \"{} {}\".format(num_lines, dims)\n",
        "\n",
        "# Prepends the line.\n",
        "if platform == \"linux\" or platform == \"linux2\":\n",
        "\tprepend_line(glove_file, gensim_file, gensim_first_line)\n",
        "else:\n",
        "\tprepend_slow(glove_file, gensim_file, gensim_first_line)"
      ],
      "metadata": {
        "id": "KIPWWjglOewe"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}